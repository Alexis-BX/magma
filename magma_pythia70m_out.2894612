[2023-04-28 13:54:27,597] [INFO] [runner.py:454:main] Using IP address of 10.134.18.11 for node g33n01
[2023-04-28 13:54:27,600] [INFO] [runner.py:553:main] cmd = jsrun -n 54 -c 7 -g 1 -a 1 -E CUDA_VISIBLE_DEVICES=0,1,2,3,4,5 -E PYTHONPATH=/autofs/nccs-svm1_home1/alexisroger/scratch/magma_webdataset:/sw/summit/xalt/1.2.1/site:/sw/summit/xalt/1.2.1/libexec /gpfs/alpine/csc499/proj-shared/env_setup/miniconda3/bin/python -u train.py --config summit_clipH_pythia70m_9.yml
[2023-04-28 13:54:45,258] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,258] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,258] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,258] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,258] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,258] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,258] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,258] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,258] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,260] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,260] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:45,259] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:46,411] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:46,411] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:46,411] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:46,411] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:46,411] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:46,411] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:47,670] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:47,670] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:47,670] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:47,670] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:47,670] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:47,670] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:48,102] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:48,102] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:48,102] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:48,102] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:48,102] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:48,102] [INFO] [comm.py:643:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=42, local_rank=0, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=6, local_rank=0, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=18, local_rank=0, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=1, local_rank=1, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=44, local_rank=2, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=23, local_rank=5, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=10, local_rank=4, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=47, local_rank=5, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=22, local_rank=4, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=11, local_rank=5, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=46, local_rank=4, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=3, local_rank=3, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=21, local_rank=3, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=30, local_rank=0, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=45, local_rank=3, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=8, local_rank=2, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=5, local_rank=5, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=20, local_rank=2, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=48, local_rank=0, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=43, local_rank=1, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=25, local_rank=1, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=19, local_rank=1, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=31, local_rank=1, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=9, local_rank=3, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=14, local_rank=2, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=7, local_rank=1, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=2, local_rank=2, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=34, local_rank=4, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=49, local_rank=1, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=24, local_rank=0, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=33, local_rank=3, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=32, local_rank=2, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=35, local_rank=5, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=12, local_rank=0, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=4, local_rank=4, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=50, local_rank=2, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=29, local_rank=5, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=51, local_rank=3, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=28, local_rank=4, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=16, local_rank=4, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,424] [INFO] [comm.py:661:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=53, local_rank=5, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=27, local_rank=3, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=15, local_rank=3, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=52, local_rank=4, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=26, local_rank=2, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=13, local_rank=1, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=37, local_rank=1, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=17, local_rank=5, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=41, local_rank=5, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=36, local_rank=0, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=39, local_rank=3, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=38, local_rank=2, world_size=54, master_addr=10.134.18.11, master_port=29500
[2023-04-28 13:54:50,423] [INFO] [comm.py:697:mpi_discovery] Discovered MPI settings of world_rank=40, local_rank=4, world_size=54, master_addr=10.134.18.11, master_port=29500
Loading NeoX language model...
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
branch 3
branch 3
does the model shrink? 986109441
branch 3
does the model shrink? 986109441
does the model shrink? 986109441
branch 3
branch 3
does the model shrink? 986109441
branch 3
branch 3
branch 3
branch 3
branch 3
does the model shrink? 986109441
does the model shrink? 986109441
branch 3
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
branch 3
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
visual size 632076800
self.transformer size is 629678080
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
branch 3
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
branch 3
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
branch 3
does the model shrink? 986109441
does the model shrink? 986109441
branch 3
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
branch 3
branch 3
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
visual size 632076800
self.transformer size is 629678080
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
branch 3
visual size 632076800
visual tower size is 632076800
branch 3
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
visual size 632076800
self.transformer size is 629678080
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=TruTransformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
e)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bi      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=Truas=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
e)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
does the model shrink? 986109441
does the model shrink? 986109441
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
does the model shrink? 986109441
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
does the model shrink? 986109441
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
does the model shrink? 986109441
visual size 632076800
visual tower size is 632076800
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
[2023-04-28 14:00:00,404] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed info: version=0.8.3+744c2ae, git-hash=744c2ae, git-branch=v2.0-summit
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (24): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (25): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (26): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (27): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (28): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (29): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (30): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
    (31): ResidualAttentionBlock(
      (ln_1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1280, out_features=5120, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=5120, out_features=1280, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
self.transformer size is 629678080
visual size 632076800
visual tower size is 632076800
visual size 632076800
visual tower size is 632076800
does the model shrink? 986109441
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
Transformer(
  (resblocks): ModuleList(
    (0): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (1): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (2): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (3): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (4): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (5): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (6): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (7): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (8): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (9): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (10): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (11): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (12): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (13): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (14): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (15): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (16): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (17): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (18): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (19): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (20): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (21): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (22): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
    (23): ResidualAttentionBlock(
      (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (attn): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
      )
      (ls_1): Identity()
      (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
      (mlp): Sequential(
        (c_fc): Linear(in_features=1024, out_features=4096, bias=True)
        (gelu): GELU(approximate=none)
        (c_proj): Linear(in_features=4096, out_features=1024, bias=True)
      )
      (ls_2): Identity()
    )
  )
)
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
does the model shrink? 986109441
[2023-04-28 14:00:21,888] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2023-04-28 14:00:21,889] [INFO] [logging.py:77:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer
[2023-04-28 14:00:21,889] [INFO] [logging.py:77:log_dist] [Rank 0] Using client Optimizer as basic optimizer
[2023-04-28 14:00:22,026] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2023-04-28 14:00:22,026] [INFO] [utils.py:55:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2023-04-28 14:00:22,026] [INFO] [logging.py:77:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer
[2023-04-28 14:00:22,027] [INFO] [stage_1_and_2.py:144:__init__] Reduce bucket size 500,000,000
[2023-04-28 14:00:22,027] [INFO] [stage_1_and_2.py:145:__init__] Allgather bucket size 500,000,000
[2023-04-28 14:00:22,027] [INFO] [stage_1_and_2.py:146:__init__] CPU Offload: False
[2023-04-28 14:00:22,027] [INFO] [stage_1_and_2.py:147:__init__] Round robin gradient partitioning: False
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Emitting ninja build file /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.45606493949890137 seconds
Time to load utils op: 0.4750640392303467 seconds
Loading extension module utils...
Time to load utils op: 0.47629499435424805 seconds
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.47060394287109375 seconds
Loading extension module utils...
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.41592931747436523 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.42934751510620117 seconds
Time to load utils op: 0.4586188793182373 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.4811670780181885 seconds
Loading extension module utils...
Time to load utils op: 0.4316747188568115 seconds
Time to load utils op: 0.47653651237487793 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.4684896469116211 seconds
Time to load utils op: 0.4697151184082031 seconds
Loading extension module utils...
Loading extension module utils...
Time to load utils op: 0.4523453712463379 seconds
Loading extension module utils...
Time to load utils op: 0.446702241897583 seconds
Time to load utils op: 0.4754910469055176 seconds
Loading extension module utils...
Time to load utils op: 0.4716625213623047 seconds
Time to load utils op: 0.45223379135131836 seconds
Loading extension module utils...
Time to load utils op: 0.47503066062927246 seconds
Time to load utils op: 0.4697592258453369 seconds
Time to load utils op: 0.4791417121887207 seconds
Time to load utils op: 0.4624166488647461 seconds
Time to load utils op: 0.4341249465942383 seconds
Time to load utils op: 0.43966245651245117 seconds
Time to load utils op: 0.45812368392944336 seconds
Time to load utils op: 0.45675182342529297 seconds
Time to load utils op: 0.4697589874267578 seconds
Time to load utils op: 0.4747352600097656 seconds
Time to load utils op: 0.4439821243286133 seconds
Time to load utils op: 0.47464489936828613 seconds
Time to load utils op: 0.47031235694885254 seconds
Time to load utils op: 0.48009514808654785 seconds
Time to load utils op: 0.4868624210357666 seconds
Time to load utils op: 0.43137407302856445 seconds
Time to load utils op: 0.48682665824890137 seconds
Time to load utils op: 0.4782755374908447 seconds
Time to load utils op: 0.48007822036743164 seconds
Time to load utils op: 0.48620176315307617 seconds
Time to load utils op: 0.4874114990234375 seconds
Time to load utils op: 0.4788691997528076 seconds
Time to load utils op: 0.47661828994750977 seconds
Time to load utils op: 0.4662919044494629 seconds
Time to load utils op: 0.47906494140625 seconds
Time to load utils op: 0.47650766372680664 seconds
Time to load utils op: 0.4846971035003662 seconds
Time to load utils op: 0.4845926761627197 seconds
Time to load utils op: 0.4774174690246582 seconds
Time to load utils op: 0.47417664527893066 seconds
Time to load utils op: 0.47134900093078613 seconds
Time to load utils op: 0.4415721893310547 seconds
Time to load utils op: 0.4832935333251953 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Emitting ninja build file /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.25174617767333984 seconds
Loading extension module utils...
Time to load utils op: 0.204559326171875 seconds
Rank: 9 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 40 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 42 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 44 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 45 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 47 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 7 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 11 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 10 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 16 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 3 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 28 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 26 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 36 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 38 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 29 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 27 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 39 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 41 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 25 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 24 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 37 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 34 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 51 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 33 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 35 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 52 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 53 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 31 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 32 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 30 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 5 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 50 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 49 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 4 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 2 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 19 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 18 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 23 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 22 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 0 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 48 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 20 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 21 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 1 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 12 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 15 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 14 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 13 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 17 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 6 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 8 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Emitting ninja build file /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.25325751304626465 seconds
Loading extension module utils...
Time to load utils op: 0.3051176071166992 seconds
Rank: 43 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Rank: 46 partition count [54, 54] and sizes[(11705126, False), (253516, False)] 
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.004048824310302734 seconds
Time to load utils op: 0.004081010818481445 seconds
Time to load utils op: 0.004081249237060547 seconds
Time to load utils op: 0.0039942264556884766 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00428318977355957 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0011701583862304688 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0009405612945556641 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0009815692901611328 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007739067077636719 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Time to load utils op: 0.000576019287109375 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0008625984191894531 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Time to load utils op: 0.0010399818420410156 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Time to load utils op: 0.0012235641479492188 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006940364837646484 seconds
Time to load utils op: 0.0005643367767333984 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.000518798828125 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.001138925552368164 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0008137226104736328 seconds
Time to load utils op: 0.0009570121765136719 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0011792182922363281 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0010807514190673828 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0009524822235107422 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Time to load utils op: 0.0004897117614746094 seconds
Time to load utils op: 0.001024007797241211 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0011038780212402344 seconds
Time to load utils op: 0.00044608116149902344 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0012445449829101562 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0008177757263183594 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0008080005645751953 seconds
Time to load utils op: 0.0006525516510009766 seconds
Time to load utils op: 0.0007898807525634766 seconds
Time to load utils op: 0.00041604042053222656 seconds
Time to load utils op: 0.0007238388061523438 seconds
Time to load utils op: 0.00039887428283691406 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0009481906890869141 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Time to load utils op: 0.00091552734375 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0009045600891113281 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0006651878356933594 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Time to load utils op: 0.0010142326354980469 seconds
Time to load utils op: 0.0005156993865966797 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Time to load utils op: 0.0012402534484863281 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0008401870727539062 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.000978231430053711 seconds
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
Time to load utils op: 0.0006368160247802734 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.000644683837890625 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0010700225830078125 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0007534027099609375 seconds
Time to load utils op: 0.0010743141174316406 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.0014646053314208984 seconds
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.001089334487915039 seconds
Time to load utils op: 0.0010132789611816406 seconds
Time to load utils op: 0.0008485317230224609 seconds
Time to load utils op: 0.0012001991271972656 seconds
[2023-04-28 14:00:30,798] [INFO] [utils.py:829:see_memory_usage] Before initializing optimizer states
[2023-04-28 14:00:30,798] [INFO] [utils.py:830:see_memory_usage] MA 2.1 GB         Max_MA 2.12 GB         CA 2.12 GB         Max_CA 2 GB 
[2023-04-28 14:00:30,799] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 91.3 GB, percent = 15.2%
[2023-04-28 14:00:30,863] [INFO] [utils.py:829:see_memory_usage] After initializing optimizer states
[2023-04-28 14:00:30,864] [INFO] [utils.py:830:see_memory_usage] MA 2.19 GB         Max_MA 2.32 GB         CA 2.35 GB         Max_CA 2 GB 
[2023-04-28 14:00:30,865] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 91.53 GB, percent = 15.2%
[2023-04-28 14:00:30,865] [INFO] [stage_1_and_2.py:520:__init__] optimizer state initialized
[2023-04-28 14:00:30,919] [INFO] [utils.py:829:see_memory_usage] After initializing ZeRO optimizer
[2023-04-28 14:00:30,920] [INFO] [utils.py:830:see_memory_usage] MA 2.19 GB         Max_MA 2.19 GB         CA 2.35 GB         Max_CA 2 GB 
[2023-04-28 14:00:30,920] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 91.55 GB, percent = 15.2%
[2023-04-28 14:00:30,922] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed Final Optimizer = AdamW
[2023-04-28 14:00:30,923] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupDecayLR
[2023-04-28 14:00:30,923] [INFO] [logging.py:77:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupDecayLR object at 0x2000a78fafa0>
[2023-04-28 14:00:30,923] [INFO] [logging.py:77:log_dist] [Rank 0] step=0, skipped=0, lr=[2e-06, 0.0008], mom=[(0.9, 0.95), (0.9, 0.95)]
[2023-04-28 14:00:30,925] [INFO] [config.py:1018:print] DeepSpeedEngine configuration:
[2023-04-28 14:00:30,925] [INFO] [config.py:1022:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2023-04-28 14:00:30,925] [INFO] [config.py:1022:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2023-04-28 14:00:30,925] [INFO] [config.py:1022:print]   amp_enabled .................. False
[2023-04-28 14:00:30,925] [INFO] [config.py:1022:print]   amp_params ................... False
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   bfloat16_enabled ............. False
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   checkpoint_parallel_write_pipeline  False
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   checkpoint_tag_validation_enabled  True
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   checkpoint_tag_validation_fail  False
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x2000859e11f0>
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   communication_data_type ...... None
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   curriculum_enabled_legacy .... False
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   curriculum_params_legacy ..... False
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   data_efficiency_enabled ...... False
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   dataloader_drop_last ......... False
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   disable_allgather ............ False
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   dump_state ................... False
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   dynamic_loss_scale_args ...... {'init_scale': 65536, 'scale_window': 250, 'delayed_shift': 2, 'min_scale': 1}
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   eigenvalue_enabled ........... False
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   eigenvalue_gas_boundary_resolution  1
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   eigenvalue_layer_num ......... 0
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   eigenvalue_max_iter .......... 100
[2023-04-28 14:00:30,926] [INFO] [config.py:1022:print]   eigenvalue_stability ......... 1e-06
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   eigenvalue_tol ............... 0.01
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   eigenvalue_verbose ........... False
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   elasticity_enabled ........... False
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   flops_profiler_config ........ {
    "enabled": false, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   fp16_auto_cast ............... False
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   fp16_enabled ................. True
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   fp16_master_weights_and_gradients  False
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   global_rank .................. 0
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   grad_accum_dtype ............. None
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   gradient_accumulation_steps .. 4
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   gradient_clipping ............ 1.0
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   gradient_predivide_factor .... 1.0
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   initial_dynamic_scale ........ 65536
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   load_universal_checkpoint .... False
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   loss_scale ................... 0
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   memory_breakdown ............. False
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   optimizer_legacy_fusion ...... False
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   optimizer_name ............... None
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   optimizer_params ............. None
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   pld_enabled .................. False
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   pld_params ................... False
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   prescale_gradients ........... False
[2023-04-28 14:00:30,927] [INFO] [config.py:1022:print]   scheduler_name ............... WarmupDecayLR
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   scheduler_params ............. {'total_num_steps': 300000, 'warmup_min_lr': [0.0, 0.0], 'warmup_max_lr': [2e-06, 0.0008], 'warmup_num_steps': 100}
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   sparse_attention ............. None
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   sparse_gradients_enabled ..... False
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   steps_per_print .............. 10
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   train_batch_size ............. 648
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   train_micro_batch_size_per_gpu  3
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   use_node_local_storage ....... False
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   wall_clock_breakdown ......... False
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   world_size ................... 54
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   zero_allow_untested_optimizer  False
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=False elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   zero_enabled ................. True
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   zero_force_ds_cpu_optimizer .. True
[2023-04-28 14:00:30,928] [INFO] [config.py:1022:print]   zero_optimization_stage ...... 2
[2023-04-28 14:00:30,928] [INFO] [config.py:1007:print_user_config]   json = {
    "train_micro_batch_size_per_gpu": 3, 
    "gradient_accumulation_steps": 4, 
    "gradient_clipping": 1.0, 
    "fp16": {
        "enabled": true, 
        "loss_scale_window": 250
    }, 
    "scheduler": {
        "type": "WarmupDecayLR", 
        "params": {
            "total_num_steps": 3.000000e+05, 
            "warmup_min_lr": [0.0, 0.0], 
            "warmup_max_lr": [2e-06, 0.0008], 
            "warmup_num_steps": 100
        }
    }, 
    "zero_optimization": {
        "stage": 2, 
        "load_from_fp32_weights": false
    }
}
Using /gpfs/alpine/scratch/alexisroger/csc499/cache/torch_extensions as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
Time to load utils op: 0.00047135353088378906 seconds
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,798] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,797] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,799] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,799] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,799] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,799] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,799] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0
[2023-04-28 14:00:49,799] [WARNING] [engine.py:2764:load_checkpoint] Unable to find latest file at /gpfs/alpine/scratch/alexisroger/csc499/magma/checkpoints/MAGMA_19M_clipH_9/latest, if trying to load latest checkpoint please ensure this file exists or pass an explicit checkpoint tag when loading a checkpoint.
Model loading failed - starting from global step 0

------------------------------------------------------------
Sender: LSF System <lsfadmin@batch4>
Subject: Job 2894612: <magma_pythia70m> in cluster <summit> Exited

Job <magma_pythia70m> was submitted from host <login5> by user <alexisroger> in cluster <summit> at Fri Apr 28 13:43:16 2023
Job was executed on host(s) <1*batch4>, in queue <batch>, as user <alexisroger> in cluster <summit> at Fri Apr 28 13:53:51 2023
                            <42*g33n01>
                            <42*g33n02>
                            <42*g33n03>
                            <42*g33n04>
                            <42*g33n05>
                            <42*g33n06>
                            <42*g33n07>
                            <42*g35n02>
                            <42*h20n03>
</ccs/home/alexisroger> was used as the home directory.
</ccs/home/alexisroger/scratch/magma_webdataset> was used as the working directory.
Started at Fri Apr 28 13:53:51 2023
Terminated at Fri Apr 28 14:01:19 2023
Results reported at Fri Apr 28 14:01:19 2023

The output (if any) is above this job summary.



PS:

Read file <magma_pythia70m_err.2894612> for stderr output of this job.

